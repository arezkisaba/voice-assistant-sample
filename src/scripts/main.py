import os
import json
import requests
import time
import argparse
import threading
import re
import tempfile
from io import BytesIO
from playsound import playsound
from ctypes import *
from contextlib import contextmanager
import sys

import speech_recognition as sr
from gtts import gTTS

OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "gemma3:12b"
SYSTEM_PROMPT = """Tu es un assistant vocal fran√ßais intelligent et serviable. 
R√©ponds de mani√®re claire et concise, id√©alement en 2-3 phrases. 
Privil√©gie la simplicit√© et la clart√© dans tes r√©ponses."""

@contextmanager
def suppress_stderr():
    stderr = sys.stderr
    devnull = open(os.devnull, 'w')
    sys.stderr = devnull
    try:
        yield
    finally:
        sys.stderr = stderr
        devnull.close()

class AssistantVocal:
    def __init__(self):
        with suppress_stderr():
            self.recognizer = sr.Recognizer()
        
        self.temp_dir = tempfile.gettempdir()
        
        self.listening = False
        self.conversation_history = []
        self.language = "fr-FR"
    
    def ecouter(self):
        with suppress_stderr():
            with sr.Microphone() as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=1.5)
                
                self.recognizer.energy_threshold = 1500
                self.recognizer.dynamic_energy_threshold = True
                self.recognizer.pause_threshold = 1.2
                self.recognizer.non_speaking_duration = 1.0
                
                print("üé§ J'√©coute...", end="", flush=True)
                
                try:
                    audio = self.recognizer.listen(
                        source, 
                        timeout=None,
                        phrase_time_limit=12
                    )
                    print(" termin√©")
                except sr.WaitTimeoutError:
                    print(" temps d'attente d√©pass√©")
                    return None
        
        try:
            if self._est_silence(audio):
                print("üîá Silence d√©tect√© - aucune entr√©e vocale")
                return None
            
            texte = None
            
            try:
                texte = self.recognizer.recognize_google(audio, language="fr-FR")
            except:
                pass
                
            if not texte:
                try:
                    options = {"language": "fr-FR", "show_all": True}
                    results = self.recognizer.recognize_google(audio, **options)
                    if isinstance(results, dict) and 'alternative' in results and results['alternative']:
                        texte = results['alternative'][0]['transcript']
                except:
                    pass
            
            if not texte:
                try:
                    texte = self.recognizer.recognize_google(audio)
                except:
                    pass
            
            if texte and len(texte.strip()) < 2:
                print("üîá D√©tection trop courte ignor√©e")
                return None
                
            if texte:
                print(f"üó£Ô∏è Vous avez dit: {texte}")
                return texte
            else:
                print("‚ùì Je n'ai pas compris ce que vous avez dit")
                return None
                
        except sr.UnknownValueError:
            print("‚ùì Je n'ai pas compris ce que vous avez dit")
            return None
        except sr.RequestError as e:
            print(f"‚ùå Erreur avec le service de reconnaissance: {e}")
            return None
            
    def _est_silence(self, audio_data):
        try:
            import numpy as np
            
            audio_array = np.frombuffer(audio_data.get_raw_data(), dtype=np.int16)
            
            rms = np.sqrt(np.mean(np.square(audio_array.astype(np.float32))))
            
            silence_threshold = 200
            
            if rms < silence_threshold:
                return True
                
            silence_percentage = np.sum(np.abs(audio_array) < 100) / len(audio_array)
            if silence_percentage > 0.9:
                return True
                
            return False
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la v√©rification du silence: {e}")
            return False
    
    def parler(self, texte):
        texte = self._nettoyer_texte(texte)
        print(f"üîä Assistant: {texte}")
        
        try:
            tts = gTTS(text=texte, lang='fr', slow=False)
            
            temp_file = os.path.join(self.temp_dir, f"assistant_vocal_{int(time.time())}.mp3")
            tts.save(temp_file)
            
            if self._check_ffplay_installed():
                speed_factor = 1.3
                cmd = f"ffplay -nodisp -autoexit -loglevel quiet -af atempo={speed_factor} {temp_file}"
                os.system(cmd)
            else:
                playsound(temp_file)
            
            try:
                os.remove(temp_file)
            except:
                pass
                
        except Exception as e:
            print(f"‚ùå Erreur lors de la synth√®se vocale: {e}")
    
    def _check_ffplay_installed(self):
        try:
            result = os.system("ffplay -version > /dev/null 2>&1")
            return result == 0
        except:
            return False
    
    def _nettoyer_texte(self, texte):
        texte = re.sub(r'(\d+)\.(\d+)', r'\1 virgule \2', texte)
        texte = re.sub(r'(\w+)\.(\w+)', r'\1 point \2', texte)
        return texte
    
    def obtenir_reponse_ollama(self, question):
        context = "\n".join([f"{'Assistant' if i%2 else 'Utilisateur'}: {msg}" 
                            for i, msg in enumerate(self.conversation_history)])
        
        prompt = f"{context}\nUtilisateur: {question}\nAssistant:"
        
        payload = {
            "model": MODEL_NAME,
            "prompt": prompt,
            "system": SYSTEM_PROMPT,
            "stream": False,
            "options": {
                "temperature": 0.7,
                "top_p": 0.9
            }
        }
        
        try:
            response = requests.post(OLLAMA_URL, json=payload)
            if response.status_code == 200:
                response_text = response.json().get("response", "")
                if len(self.conversation_history) > 10:
                    self.conversation_history = self.conversation_history[-10:]
                self.conversation_history.append(question)
                self.conversation_history.append(response_text)
                return response_text
            else:
                print(f"‚ùå Erreur Ollama: {response.status_code}")
                return "D√©sol√©, j'ai rencontr√© une erreur de communication avec le mod√®le."
        except Exception as e:
            print(f"‚ùå Exception lors de l'appel √† Ollama: {e}")
            return "D√©sol√©, je ne peux pas acc√©der au mod√®le pour le moment."
    
    def demarrer_conversation(self):
        self.listening = True
        self.parler("Bonjour! Je suis votre assistant vocal fran√ßais. Comment puis-je vous aider?")
        
        while self.listening:
            question = self.ecouter()
            if question:
                mots_arret = ["au revoir", "arr√™te", "stop", "termine", "bye", "goodbye", "exit", "quit", "ciao"]
                if any(mot in question.lower() for mot in mots_arret):
                    self.parler("Au revoir! √Ä bient√¥t.")
                    self.listening = False
                    break
                    
                reponse = self.obtenir_reponse_ollama(question)
                self.parler(reponse)
            time.sleep(0.5)

def verifier_ollama():
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code != 200:
            return False, "Ollama n'est pas accessible"
        
        models = response.json().get("models", [])
        model_names = [model.get("name") for model in models]
        
        if MODEL_NAME not in model_names:
            return False, f"Le mod√®le {MODEL_NAME} n'est pas t√©l√©charg√©. Ex√©cutez: ollama pull {MODEL_NAME}"
        
        return True, "OK"
    except Exception as e:
        return False, f"Erreur lors de la v√©rification d'Ollama: {e}"

def main():
    parser = argparse.ArgumentParser(description="Assistant Vocal Fran√ßais avec Ollama et Gemma 3:12B")
    parser.add_argument("--texte", action="store_true", help="Mode texte uniquement (sans voix)")
    args = parser.parse_args()
    
    print("ü§ñ Assistant Vocal Fran√ßais avec Ollama et Gemma 3:12B")
    print("------------------------------------------------")
    
    ollama_ok, message = verifier_ollama()
    if not ollama_ok:
        print(f"‚ùå {message}")
        return
    
    print(f"‚úÖ Ollama est pr√™t avec le mod√®le {MODEL_NAME}")
    
    if args.texte:
        print("\nüìù Mode texte activ√© (tapez 'quitter' pour sortir)")
        assistant = AssistantVocal()
        while True:
            question = input("\n‚û°Ô∏è Vous: ")
            if question.lower() in ["quitter", "exit", "q"]:
                break
            reponse = assistant.obtenir_reponse_ollama(question)
            print(f"ü§ñ Assistant: {reponse}")
    else:
        try:
            assistant = AssistantVocal()
            print("\nüé§ Mode vocal activ√© (dites 'au revoir' pour terminer)")
            assistant.demarrer_conversation()
        except KeyboardInterrupt:
            print("\nüëã Assistant vocal arr√™t√©.")
    
if __name__ == "__main__":
    main()